#!/usr/bin/env python3
"""
Training script for the Neural Critic model.

This script trains the critic to score (program, task) pairs for:
- Plausibility: is this a valid/reasonable program?
- Generalization: will this program work on unseen examples?

Training data is generated by:
1. Creating synthetic tasks with known programs
2. Generating positive examples (correct programs)
3. Generating negative examples (incorrect/partial programs)
4. Training the critic to distinguish good from bad programs

Usage:
    python -m juris_agi.train.train_critic --epochs 100 --output models/critic.pt
"""

import argparse
import random
from dataclasses import dataclass, field
from pathlib import Path
from typing import List, Optional, Dict, Any, Tuple
import json

import numpy as np

from ..core.types import Grid, ARCTask, ARCPair
from ..dsl.ast import ASTNode, PrimitiveNode, ComposeNode, LiteralNode, walk_ast
from ..dsl.primitives import list_primitives
from ..dsl.interpreter import DSLInterpreter
from ..cre.critic_neural import (
    TORCH_AVAILABLE,
    CriticConfig,
    NeuralCriticScore,
)
from .train_sketcher import (
    generate_random_grid,
    generate_random_program,
    generate_synthetic_task,
    SketcherTrainingConfig,
)

if TORCH_AVAILABLE:
    import torch
    import torch.nn as nn
    import torch.optim as optim
    from torch.utils.data import Dataset, DataLoader
    from ..cre.critic_neural import GeneralizationCriticModel


# =============================================================================
# Configuration
# =============================================================================

@dataclass
class CriticTrainingConfig:
    """Configuration for critic training."""
    # Model config
    model_config: CriticConfig = field(default_factory=CriticConfig)

    # Training hyperparameters
    batch_size: int = 32
    epochs: int = 100
    learning_rate: float = 1e-4
    weight_decay: float = 1e-5
    warmup_steps: int = 100
    gradient_clip: float = 1.0

    # Data generation
    num_train_samples: int = 10000
    num_val_samples: int = 1000
    negative_ratio: float = 0.5  # Ratio of negative examples
    max_program_length: int = 4
    min_grid_size: int = 3
    max_grid_size: int = 10
    num_train_pairs: int = 3

    # Checkpointing
    checkpoint_every: int = 10
    output_dir: str = "models"

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary."""
        return {
            "batch_size": self.batch_size,
            "epochs": self.epochs,
            "learning_rate": self.learning_rate,
            "weight_decay": self.weight_decay,
            "negative_ratio": self.negative_ratio,
            "num_train_samples": self.num_train_samples,
        }


# =============================================================================
# Negative Example Generation
# =============================================================================

def mutate_program(program: ASTNode) -> ASTNode:
    """Mutate a program to create a negative example."""
    mutation_type = random.choice(["swap_primitive", "remove_step", "add_step", "change_arg"])

    primitives = list_primitives()

    if mutation_type == "swap_primitive":
        # Swap a primitive with a random one
        nodes = walk_ast(program)
        prim_nodes = [n for n in nodes if isinstance(n, PrimitiveNode)]

        if prim_nodes:
            target = random.choice(prim_nodes)
            new_name = random.choice(primitives)
            return PrimitiveNode(new_name)

    elif mutation_type == "remove_step":
        # Remove a step from composition
        if isinstance(program, ComposeNode) and len(program.operations) > 1:
            idx = random.randint(0, len(program.operations) - 1)
            new_ops = program.operations[:idx] + program.operations[idx + 1:]
            if len(new_ops) == 1:
                return new_ops[0]
            return ComposeNode(new_ops)

    elif mutation_type == "add_step":
        # Add a random step
        new_prim = PrimitiveNode(random.choice(primitives))
        if isinstance(program, ComposeNode):
            new_ops = list(program.operations) + [new_prim]
            return ComposeNode(new_ops)
        return ComposeNode([program, new_prim])

    elif mutation_type == "change_arg":
        # Change an argument
        if isinstance(program, PrimitiveNode) and program.args:
            new_args = list(program.args)
            idx = random.randint(0, len(new_args) - 1)
            if isinstance(new_args[idx], LiteralNode):
                if isinstance(new_args[idx].value, int):
                    new_args[idx] = LiteralNode(new_args[idx].value + random.choice([-1, 1]))
            return PrimitiveNode(program.name, new_args)

    # Fallback: return a random program
    new_prog, _ = generate_random_program(2)
    return new_prog


def generate_negative_program(task: ARCTask) -> ASTNode:
    """Generate a program that doesn't solve the task."""
    # Generate a completely random program
    program, _ = generate_random_program(random.randint(1, 3))
    return program


# =============================================================================
# PyTorch Dataset
# =============================================================================

if TORCH_AVAILABLE:

    class CriticDataset(Dataset):
        """Dataset for critic training with positive and negative examples."""

        def __init__(
            self,
            num_samples: int,
            config: CriticTrainingConfig,
        ):
            self.config = config
            self.samples = []

            # Create sketcher config for task generation
            sketcher_config = SketcherTrainingConfig(
                max_program_length=config.max_program_length,
                min_grid_size=config.min_grid_size,
                max_grid_size=config.max_grid_size,
                num_train_pairs=config.num_train_pairs,
            )

            print(f"Generating {num_samples} critic training samples...")
            interpreter = DSLInterpreter()

            for i in range(num_samples):
                # Generate a task with its correct program
                task, correct_program, primitives = generate_synthetic_task(sketcher_config)

                # Decide if this is a positive or negative example
                is_positive = random.random() > config.negative_ratio

                if is_positive:
                    program = correct_program
                    # Labels: high plausibility, high generalization
                    labels = {
                        "plausibility": 0.9 + random.uniform(-0.05, 0.05),
                        "generalization": 0.9 + random.uniform(-0.05, 0.05),
                        "confidence": 0.9,
                    }
                else:
                    # Generate negative program
                    if random.random() < 0.5:
                        program = mutate_program(correct_program)
                    else:
                        program = generate_negative_program(task)

                    # Labels: low plausibility/generalization
                    labels = {
                        "plausibility": 0.2 + random.uniform(-0.1, 0.1),
                        "generalization": 0.2 + random.uniform(-0.1, 0.1),
                        "confidence": 0.7,
                    }

                    # Verify it's actually wrong
                    try:
                        for pair in task.train:
                            result = interpreter.eval(program, {"grid": pair.input})
                            if isinstance(result, Grid) and result == pair.output:
                                # Accidentally correct, boost labels
                                labels["plausibility"] = 0.7
                                labels["generalization"] = 0.6
                                break
                    except Exception:
                        pass  # Errors mean it's definitely wrong

                self.samples.append({
                    "task": task,
                    "program": program,
                    "labels": labels,
                    "is_positive": is_positive,
                })

                if (i + 1) % 1000 == 0:
                    print(f"  Generated {i + 1}/{num_samples} samples")

        def __len__(self) -> int:
            return len(self.samples)

        def __getitem__(self, idx: int) -> Dict[str, Any]:
            return self.samples[idx]


    def critic_collate_fn(batch: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Collate function for critic DataLoader."""
        # Extract programs and tasks
        programs = [s["program"] for s in batch]
        tasks = [s["task"] for s in batch]

        # Convert labels to tensors
        plausibility = torch.tensor(
            [s["labels"]["plausibility"] for s in batch],
            dtype=torch.float,
        )
        generalization = torch.tensor(
            [s["labels"]["generalization"] for s in batch],
            dtype=torch.float,
        )
        confidence = torch.tensor(
            [s["labels"]["confidence"] for s in batch],
            dtype=torch.float,
        )

        # Convert grids to tensors - use first training pair from each task
        input_grids = []
        output_grids = []

        for task in tasks:
            if task.train:
                pair = task.train[0]
                input_grids.append(torch.tensor(pair.input.data, dtype=torch.long))
                output_grids.append(torch.tensor(pair.output.data, dtype=torch.long))

        return {
            "programs": programs,
            "tasks": tasks,
            "input_grids": input_grids,
            "output_grids": output_grids,
            "plausibility": plausibility,
            "generalization": generalization,
            "confidence": confidence,
        }


# =============================================================================
# Trainer
# =============================================================================

class CriticTrainer:
    """Trainer for the neural critic model."""

    def __init__(self, config: CriticTrainingConfig):
        self.config = config

        if not TORCH_AVAILABLE:
            raise RuntimeError("PyTorch is required for training")

        # Create model
        self.model = GeneralizationCriticModel(config.model_config)
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model.to(self.device)

        # Optimizer
        self.optimizer = optim.AdamW(
            self.model.parameters(),
            lr=config.learning_rate,
            weight_decay=config.weight_decay,
        )

        # Loss function (MSE for regression)
        self.criterion = nn.MSELoss()

        # Training state
        self.current_epoch = 0
        self.global_step = 0
        self.best_val_loss = float("inf")

    def train_epoch(self, dataloader: "DataLoader") -> Dict[str, float]:
        """Train for one epoch."""
        self.model.train()
        total_loss = 0.0
        total_plaus_loss = 0.0
        total_gen_loss = 0.0
        num_batches = 0

        for batch in dataloader:
            self.optimizer.zero_grad()

            # Move data to device
            programs = batch["programs"]
            input_grids = [g.unsqueeze(0).to(self.device) for g in batch["input_grids"]]
            output_grids = [g.unsqueeze(0).to(self.device) for g in batch["output_grids"]]

            target_plaus = batch["plausibility"].to(self.device)
            target_gen = batch["generalization"].to(self.device)

            # Forward pass
            pred_plaus, pred_gen, pred_conf = self.model(
                programs, input_grids, output_grids
            )

            # Compute losses
            plaus_loss = self.criterion(pred_plaus, target_plaus)
            gen_loss = self.criterion(pred_gen, target_gen)
            loss = plaus_loss + gen_loss

            # Backward pass
            loss.backward()

            # Gradient clipping
            torch.nn.utils.clip_grad_norm_(
                self.model.parameters(),
                self.config.gradient_clip,
            )

            self.optimizer.step()

            total_loss += loss.item()
            total_plaus_loss += plaus_loss.item()
            total_gen_loss += gen_loss.item()
            num_batches += 1
            self.global_step += 1

        return {
            "loss": total_loss / max(1, num_batches),
            "plausibility_loss": total_plaus_loss / max(1, num_batches),
            "generalization_loss": total_gen_loss / max(1, num_batches),
        }

    def validate(self, dataloader: "DataLoader") -> Dict[str, float]:
        """Validate the model."""
        self.model.eval()
        total_loss = 0.0
        total_plaus_loss = 0.0
        total_gen_loss = 0.0
        num_batches = 0

        with torch.no_grad():
            for batch in dataloader:
                programs = batch["programs"]
                input_grids = [g.unsqueeze(0).to(self.device) for g in batch["input_grids"]]
                output_grids = [g.unsqueeze(0).to(self.device) for g in batch["output_grids"]]

                target_plaus = batch["plausibility"].to(self.device)
                target_gen = batch["generalization"].to(self.device)

                pred_plaus, pred_gen, pred_conf = self.model(
                    programs, input_grids, output_grids
                )

                plaus_loss = self.criterion(pred_plaus, target_plaus)
                gen_loss = self.criterion(pred_gen, target_gen)
                loss = plaus_loss + gen_loss

                total_loss += loss.item()
                total_plaus_loss += plaus_loss.item()
                total_gen_loss += gen_loss.item()
                num_batches += 1

        return {
            "loss": total_loss / max(1, num_batches),
            "plausibility_loss": total_plaus_loss / max(1, num_batches),
            "generalization_loss": total_gen_loss / max(1, num_batches),
        }

    def save_checkpoint(self, path: str) -> None:
        """Save model checkpoint."""
        torch.save({
            "model_state_dict": self.model.state_dict(),
            "optimizer_state_dict": self.optimizer.state_dict(),
            "epoch": self.current_epoch,
            "global_step": self.global_step,
            "best_val_loss": self.best_val_loss,
            "config": self.config.to_dict(),
        }, path)

    def load_checkpoint(self, path: str) -> None:
        """Load model checkpoint."""
        checkpoint = torch.load(path, map_location=self.device)
        self.model.load_state_dict(checkpoint["model_state_dict"])
        self.optimizer.load_state_dict(checkpoint["optimizer_state_dict"])
        self.current_epoch = checkpoint["epoch"]
        self.global_step = checkpoint["global_step"]
        self.best_val_loss = checkpoint["best_val_loss"]

    def train(
        self,
        train_dataset: "CriticDataset",
        val_dataset: "CriticDataset",
    ) -> Dict[str, List[float]]:
        """Full training loop."""
        train_loader = DataLoader(
            train_dataset,
            batch_size=self.config.batch_size,
            shuffle=True,
            collate_fn=critic_collate_fn,
        )
        val_loader = DataLoader(
            val_dataset,
            batch_size=self.config.batch_size,
            shuffle=False,
            collate_fn=critic_collate_fn,
        )

        history = {
            "train_loss": [],
            "train_plaus_loss": [],
            "train_gen_loss": [],
            "val_loss": [],
            "val_plaus_loss": [],
            "val_gen_loss": [],
        }

        output_dir = Path(self.config.output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)

        for epoch in range(self.config.epochs):
            self.current_epoch = epoch

            # Train
            train_metrics = self.train_epoch(train_loader)
            history["train_loss"].append(train_metrics["loss"])
            history["train_plaus_loss"].append(train_metrics["plausibility_loss"])
            history["train_gen_loss"].append(train_metrics["generalization_loss"])

            # Validate
            val_metrics = self.validate(val_loader)
            history["val_loss"].append(val_metrics["loss"])
            history["val_plaus_loss"].append(val_metrics["plausibility_loss"])
            history["val_gen_loss"].append(val_metrics["generalization_loss"])

            print(f"Epoch {epoch + 1}/{self.config.epochs}: "
                  f"train_loss={train_metrics['loss']:.4f}, "
                  f"val_loss={val_metrics['loss']:.4f}")

            # Save best model
            if val_metrics["loss"] < self.best_val_loss:
                self.best_val_loss = val_metrics["loss"]
                self.save_checkpoint(str(output_dir / "critic_best.pt"))
                print(f"  -> New best model saved!")

            # Periodic checkpoint
            if (epoch + 1) % self.config.checkpoint_every == 0:
                self.save_checkpoint(str(output_dir / f"critic_epoch_{epoch + 1}.pt"))

        # Save final model
        self.save_checkpoint(str(output_dir / "critic_final.pt"))

        return history


# =============================================================================
# Main
# =============================================================================

def main():
    """Main entry point for training."""
    parser = argparse.ArgumentParser(description="Train the neural critic model")

    parser.add_argument("--epochs", type=int, default=100, help="Number of epochs")
    parser.add_argument("--batch-size", type=int, default=32, help="Batch size")
    parser.add_argument("--lr", type=float, default=1e-4, help="Learning rate")
    parser.add_argument("--train-samples", type=int, default=10000, help="Training samples")
    parser.add_argument("--val-samples", type=int, default=1000, help="Validation samples")
    parser.add_argument("--negative-ratio", type=float, default=0.5, help="Negative example ratio")
    parser.add_argument("--output", type=str, default="models", help="Output directory")
    parser.add_argument("--seed", type=int, default=42, help="Random seed")

    args = parser.parse_args()

    if not TORCH_AVAILABLE:
        print("ERROR: PyTorch is required for training")
        return 1

    # Set seeds
    random.seed(args.seed)
    np.random.seed(args.seed)
    torch.manual_seed(args.seed)

    # Create config
    config = CriticTrainingConfig(
        epochs=args.epochs,
        batch_size=args.batch_size,
        learning_rate=args.lr,
        num_train_samples=args.train_samples,
        num_val_samples=args.val_samples,
        negative_ratio=args.negative_ratio,
        output_dir=args.output,
    )

    # Create datasets
    print("Creating training dataset...")
    train_dataset = CriticDataset(config.num_train_samples, config)

    print("Creating validation dataset...")
    val_dataset = CriticDataset(config.num_val_samples, config)

    # Create trainer and train
    trainer = CriticTrainer(config)
    print(f"\nTraining on {trainer.device}")
    print(f"Model parameters: {sum(p.numel() for p in trainer.model.parameters()):,}")

    history = trainer.train(train_dataset, val_dataset)

    # Save history
    output_dir = Path(args.output)
    with open(output_dir / "critic_training_history.json", "w") as f:
        json.dump(history, f, indent=2)

    print("\nTraining complete!")
    print(f"Best validation loss: {trainer.best_val_loss:.4f}")
    print(f"Models saved to: {args.output}")

    return 0


if __name__ == "__main__":
    exit(main())
